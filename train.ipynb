{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNmSpeIyFajQh1MEC/qEfEF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/spaceluvr/face-recognition-attendance-system-/blob/main/train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "myolob3ihVW9",
        "outputId": "c4bdfab7-0418-47e9-8b96-cac956599dd0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting face_recognition\n",
            "  Downloading face_recognition-1.3.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting face-recognition-models>=0.3.0 (from face_recognition)\n",
            "  Downloading face_recognition_models-0.3.0.tar.gz (100.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.1/100.1 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.10/dist-packages (from face_recognition) (8.1.7)\n",
            "Requirement already satisfied: dlib>=19.7 in /usr/local/lib/python3.10/dist-packages (from face_recognition) (19.24.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from face_recognition) (1.23.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from face_recognition) (9.4.0)\n",
            "Building wheels for collected packages: face-recognition-models\n",
            "  Building wheel for face-recognition-models (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for face-recognition-models: filename=face_recognition_models-0.3.0-py2.py3-none-any.whl size=100566171 sha256=9bcfc2a613daa24a43716ec96a90024b9dff1f33f0bfd0593f81c379d060c1b1\n",
            "  Stored in directory: /root/.cache/pip/wheels/7a/eb/cf/e9eced74122b679557f597bb7c8e4c739cfcac526db1fd523d\n",
            "Successfully built face-recognition-models\n",
            "Installing collected packages: face-recognition-models, face_recognition\n",
            "Successfully installed face-recognition-models-0.3.0 face_recognition-1.3.0\n"
          ]
        }
      ],
      "source": [
        "!pip install face_recognition"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(\"GPU available:\", tf.config.list_physical_devices(\"GPU\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "koyZ0esGiDfL",
        "outputId": "77a39525-8604-4c4e-db8b-62e426127505"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU available: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "dataset_folder = '/content/drive/My Drive/LMS 2.0/'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "roMUwz0SiU07",
        "outputId": "2e8b8899-32e1-4175-83e5-b53bcb76d418"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "import face_recognition\n",
        "import pickle\n",
        "from IPython.display import display\n",
        "\n",
        "DEFAULT_ENCODINGS_PATH = Path(\"/content/drive/MyDrive/LMS 2.0/output/encodings.pkl\")\n",
        "\n",
        "Path(\"training\").mkdir(exist_ok=True)\n",
        "Path(\"output\").mkdir(exist_ok=True)\n",
        "Path(\"validation\").mkdir(exist_ok=True)"
      ],
      "metadata": {
        "id": "LU6qj4oKiGOM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_known_faces(\n",
        "        model: str = \"hog\", encodings_location: Path = DEFAULT_ENCODINGS_PATH\n",
        ") -> None:\n",
        "    names = []\n",
        "    encodings = []\n",
        "    for filepath in Path(\"/content/drive/MyDrive/LMS 2.0/training\").glob(\"*/*\"):\n",
        "        if filepath.name.endswith(\".DS_Store\"):\n",
        "            continue\n",
        "        name = filepath.parent.name\n",
        "        image = face_recognition.load_image_file(filepath)\n",
        "\n",
        "        face_locations = face_recognition.face_locations(image, model=model)\n",
        "        face_encodings = face_recognition.face_encodings(image, face_locations)\n",
        "\n",
        "        for encoding in face_encodings:\n",
        "            names.append(name)\n",
        "            encodings.append(encoding)\n",
        "\n",
        "        name_encodings = {\"names\": names, \"encodings\": encodings}\n",
        "        with encodings_location.open(mode=\"wb\") as f:\n",
        "            pickle.dump(name_encodings, f)"
      ],
      "metadata": {
        "id": "_vyoqnD-iIzx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encode_known_faces()"
      ],
      "metadata": {
        "id": "jtsn2RAUiMDU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "from collections import Counter\n",
        "from PIL import Image, ImageDraw\n",
        "\n",
        "import face_recognition\n",
        "import pickle\n",
        "\n",
        "\n",
        "DEFAULT_ENCODINGS_PATH = Path(\"/content/drive/MyDrive/LMS 2.0/output/encodings.pkl\")\n",
        "\n",
        "Path(\"training\").mkdir(exist_ok=True)\n",
        "Path(\"output\").mkdir(exist_ok=True)\n",
        "Path(\"validation\").mkdir(exist_ok=True)\n",
        "\n",
        "\n",
        "def recognize_faces(\n",
        "        input_image,\n",
        "        model: str = \"hog\",\n",
        "        encodings_location: Path = DEFAULT_ENCODINGS_PATH,\n",
        ") -> None:\n",
        "    with encodings_location.open(mode=\"rb\") as f:\n",
        "        loaded_encodings = pickle.load(f)\n",
        "\n",
        "\n",
        "    input_face_locations = face_recognition.face_locations(\n",
        "        input_image, model=model\n",
        "    )\n",
        "\n",
        "    input_face_encodings = face_recognition.face_encodings(\n",
        "        input_image, input_face_locations\n",
        "    )\n",
        "\n",
        "    recognized_name = \"Unknown\"\n",
        "\n",
        "    for bounding_box, unknown_encoding in zip(\n",
        "            input_face_locations, input_face_encodings\n",
        "    ):\n",
        "        name = _recognize_face(unknown_encoding, loaded_encodings)\n",
        "        if name != \"Unknown\":\n",
        "          recognized_name = name\n",
        "\n",
        "    return recognized_name\n",
        "\n",
        "\n",
        "def _recognize_face(unknown_encoding, loaded_encodings, similarity_threshold=0.5):\n",
        "    boolean_matches = face_recognition.compare_faces(\n",
        "        loaded_encodings[\"encodings\"], unknown_encoding, tolerance=similarity_threshold\n",
        "    )\n",
        "\n",
        "    # this is a list due to the model training on multiple photos, hence one  person will have multiple encodings\n",
        "    recognized_names = [name for match, name in zip(boolean_matches, loaded_encodings[\"names\"]) if match]\n",
        "\n",
        "    if recognized_names:  # checks if the list is empty or not\n",
        "        votes = Counter(recognized_names)  # returns a dictionary containig the names and the count of occurence of each\n",
        "        most_common_name = votes.most_common(1)[0][0]  # most_common(1) returns a list of tuples containing the most_common values. It selects the first one and returns that\n",
        "        return most_common_name\n",
        "    else:\n",
        "        return \"Unknown\""
      ],
      "metadata": {
        "id": "xVmlhDgIiOn3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Javascript, HTML, JSON\n",
        "import base64\n",
        "import io\n",
        "from google.colab import output\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Define the process_frame function to process each frame\n",
        "\n",
        "def process_frames(framesData):\n",
        "    names = []\n",
        "    #print(\"Entering for loop\")\n",
        "    for dataURL in framesData:\n",
        "        #print(\"Entered for loop\")\n",
        "        try:\n",
        "            if len(dataURL) <= 6:\n",
        "              continue\n",
        "            #print(len(dataURL))\n",
        "            image_bytes = base64.b64decode(dataURL.split(',')[1])\n",
        "            #print(\"Step 1 done\")\n",
        "            pil_image = Image.open(io.BytesIO(image_bytes))\n",
        "            image = np.array(pil_image)\n",
        "            #print(\"Step 2 done\")\n",
        "            #print(\"Calling function\")\n",
        "            name = recognize_faces(image, model=\"hog\")\n",
        "            #print(\"Name Returned, appending now\")\n",
        "            names.append(name)\n",
        "        except Exception as e:\n",
        "            print(\"-----------------\")\n",
        "            print(\"Error processing frame:\", str(e))\n",
        "            print(\"-----------------\")\n",
        "\n",
        "    #print(names)\n",
        "    counter = Counter(names)\n",
        "    if counter:\n",
        "      name = counter.most_common(1)[0][0]\n",
        "      if name == \"Unknown\":\n",
        "        print(\"Face not matched, please try again\")\n",
        "      else:\n",
        "        print(f\"Attendance Marked for {name}\")\n",
        "    else:\n",
        "      print(\"Error fetching frames, please try again\")\n",
        "\n",
        "\n",
        "output.register_callback('process_frames', process_frames)\n",
        "\n",
        "# JavaScript code to access the webcam and display the video feed\n",
        "js_code = \"\"\"\n",
        "const videoElement = document.createElement('video');\n",
        "document.body.appendChild(videoElement);\n",
        "\n",
        "navigator.mediaDevices.getUserMedia({ video: true })\n",
        "  .then(function(stream) {\n",
        "    videoElement.srcObject = stream;\n",
        "    videoElement.play();\n",
        "    videoElement.style.transform = 'scaleX(-1)';\n",
        "  })\n",
        "  .catch(function(error) {\n",
        "    console.error('Error accessing the webcam:', error);\n",
        "  });\n",
        "\n",
        "  let captureInterval;\n",
        "  let framesData = [];\n",
        "\n",
        "  function captureFrame() {\n",
        "  const canvas = document.createElement('canvas');\n",
        "  const context = canvas.getContext('2d');\n",
        "  canvas.width = videoElement.videoWidth;\n",
        "  canvas.height = videoElement.videoHeight;\n",
        "  context.drawImage(videoElement, 0, 0, canvas.width, canvas.height);\n",
        "\n",
        "  const dataURL = canvas.toDataURL('image/jpeg');\n",
        "  console.log(dataURL)\n",
        "  framesData.push(dataURL);\n",
        "  console.log('Frame Captured');\n",
        "\n",
        "  if (framesData.length >= 6) {\n",
        "    clearInterval(captureInterval);\n",
        "    google.colab.kernel.invokeFunction('process_frames', [framesData]);\n",
        "    console.log('function called')\n",
        "  }\n",
        "}\n",
        "\n",
        "captureInterval = setInterval(captureFrame, 1000);\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Display the video feed in the Colab notebook\n",
        "display(Javascript(js_code))\n"
      ],
      "metadata": {
        "id": "KyEPyRotEfY_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "js_code = \"\"\"\n",
        "const videoElement = document.createElement('video');\n",
        "document.body.appendChild(videoElement);\n",
        "\n",
        "navigator.mediaDevices.getUserMedia({ video: true })\n",
        "  .then(function(stream) {\n",
        "    videoElement.srcObject = stream;\n",
        "    videoElement.play();\n",
        "    videoElement.style.transform = 'scaleX(-1)';\n",
        "  })\n",
        "  .catch(function(error) {\n",
        "    console.error('Error accessing the webcam:', error);\n",
        "  });\n",
        "\n",
        "  let captureInterval;\n",
        "  let framesData = [];\n",
        "\n",
        "  function captureFrame() {\n",
        "  const canvas = document.createElement('canvas');\n",
        "  const context = canvas.getContext('2d');\n",
        "  canvas.width = videoElement.videoWidth;\n",
        "  canvas.height = videoElement.videoHeight;\n",
        "  context.drawImage(videoElement, 0, 0, canvas.width, canvas.height);\n",
        "\n",
        "  const dataURL = canvas.toDataURL('image/jpeg');\n",
        "  console.log(dataURL)\n",
        "  framesData.push(dataURL);\n",
        "  console.log('Frame Captured');\n",
        "\n",
        "}\n",
        "\n",
        "captureInterval = setInterval(captureFrame, 1000);\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "mnCmRGnjKISC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yQUq9iFwFdYM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}